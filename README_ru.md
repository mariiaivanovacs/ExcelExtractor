РАСПОЗНАВАНИЕ ТЕКСТА ЦЕЛЬ ПРОЕКТА: ИЗВЛЕЧЕНИЕ ТЕКСТА ИЗ ТАБЛИЦ НА ИЗОБРАЖЕНИЯХ И СОХРАНЕНИЕ РЕЗУЛЬТАТА В CSV-ФАЙЛ (Опциональная визуализация результатов)

ФАЙЛЫ В ОСНОВНОМ PIPELINE:

utils/preprocessing.py
src/clean_white_words.py - зависит от аргумента - очищает ячейки от черных границ или удаляет белые ячейки/blobs
src/try_blobs.py (из cells в blobs)
src/resize.py (изменение размера изображений words до стандартного размера (100 X 16 pixels))
experiment/improve_quality.py (улучшение качества изображений words перед идентификацией символов)
src/try_blobs.py (из blobs в words)
src/seg_cells.py (из words в characters) (на этом этапе characters имеют размер 32 X 32 pixels)
src/find_size.py (для рассоединения слишком близких к друг другу символов)
models/train_number_other.py - скрипт для обучения классификатора NUMBER и OTHER
src/sort_csv.py - для сортировки имен файлов в разных csv-файлах для 1. удобства чтения и 2. избежания ошибок

experiment/enhanced_cell_type_detector.py - проверяет каждое изображение blob и сохраняет его в numbers_latest.csv или other_latest.csv

Изначально src/test_character_classifier.py использовался для идентификации типа слова. Однако enhanced_cell_type_detector с использованием OCR более точен, хотя не может идентифицировать точные буквы, но может различать числа и слова

Важное примечание: Почему классифицировать именно blobs? Некоторые digits (characters) могут быть повреждены или нераспознаваемы, что приведет к их исключению из конечного code flow

в моем текущем pipeline - 36 файлов, идентифицированных со слишком широкими characters, успешно заменены / разделены

models/fine_tuned_real_data_classifier.keras - CNN модель для распознавания digits (0-9)

Финальная production модель, достигающая 100% точности на реальных тестовых данных
src/test_digits_model.py - запускает построенную CNN модель для предсказания чисел
предсказания хранятся в experiment/predictions.csv

src/combine_predictions_to_table.py - финальный скрипт для восстановления полной таблицы

Объединяет предсказания отдельных characters обратно в words и cells
Создает CSV-выход (data/csv/reconstructed_table.csv) с 21 строкой × 20 столбцами
Генерирует визуализацию (results/table_visualization.png), показывающую структуру таблицы

ДЕТАЛЬНОЕ ОБЪЯСНЕНИЕ ОБУЧЕНИЯ CNN ДЛЯ РАСПОЗНАВАНИЯ DIGITS

1.train_number_keras_improved.py - начальная модель на синтетических данных (99.25% на синтетических, провалилась на реальных)
2.train_for_real_data.py - первая модель на реальных данных, соответствующая полярности изображения (точность 62.5%)
3.train_improved_for_real_data.py - попытка улучшенной глубокой модели (точность 33.3%, overfitting)
4.train_real_data_focused.py - сфокусированная модель с лучшей регуляризацией (точность 40%)
5.fine_tune_on_real_data.py - подход fine-tuning с использованием базовой модели из шага 2 Fine-tuned на 15 реальных изображениях characters с 20-кратным data augmentation (всего 300 образцов) Результат: общая точность около 80%, лучшая модель по сравнению со всеми остальными
Самая большая проблема: Синтетические данные не смогли достичь тех же параметров, что и реальные данные, несмотря на реализацию data augmentation и успешные показатели в тестах на синтетических данных. Успешные результаты только после добавления образцов реальных данных в модель


Объяснения\ аннотации ПАПОК:


blobs: папка для всех строк, найденных в cells

cells_cleaned: папка для всех разделенных изображений каждой cell

characters: каждый character разделен + добавлено padding для размера 32 X 32 pixels

data: хранилище для входных и выходных данных + некоторые csv-файлы
experiment: папка для тестирования / выполнения новых идей. Использовалась в основном для идентификации features для обучения модели (RandomForest или XGBOOST - Провал: точность: 60%%)

mnt: папка для хранения результатов, оценки результатов выполнения модели

models: папка для обучения моделей (CNNs) + сохраненные файлы RandomForest, Knn, XGBOOST, scalel и label_encoder (все не используются, были на месте во время разработки) Оставлены для целей будущего развития

results: папка для временных исходов, результатов функций, может быть очищена без потери чего-либо важного

src: папка для основного компонентного файла, изначально была создана для обучения модели предсказания числа, в настоящее время большинство файлов связаны с data preprocessing в плане разделения/извлечения words и characters из изображений cells + некоторые utility

steps_out: папка для основного результата начальной/первой preprocessing изображения таблицы

temporary_compare: статическая папка для хранения некоторых результатов внутренних этапов - резервная копия важного анализа изображений test, tests_2: папки, используемые для обучения небольшими batch, выполнения, тестового запуска точности моделей

utils: папка для начальной preprocessing таблицы, обнаружения линий.

words: разделенные, не-padded words

words_production: разделенные, padded, извлеченные words


ОСНОВНЫЕ ОПРЕДЕЛЕННЫЕ ЭТАПЫ:

Preprocess table 
Cut the table correctly 
Detect lines in table 
seg into cells 
prepare cells (remove black boundaries so no errors in blobs) 
Detect and extract blobs 
Detect and extract words in blobs
Detect characters and extract (основной pivot, возможное будущее направление, идентификация по words, а не characters) 
Prepare characters 
Train CNN to identify if the word is NUMBER or OTHER Train CNN to identify digits 0-9 
Apply and store result in csv and visualize


ТЕКУЩИЙ ПОЛНЫЙ УСПЕХ: 
Preprocess table и корректное извлечение всех cells ✅ 
Корректное извлечение всех blobs и всех words ✅ 
Обучение CNN для идентификации digits 0-9 (около 85% точности - лучший результат) ✅
 Большинство blobs идентифицированы корректно ✅


ЧТО УЯЗВИМО В ТЕКУЩИХ РЕЗУЛЬТАТАХ

1.Если characters являются числами, они почти в 95% случаев разделены корректно Однако для букв это не так, большинство текущих буквенных characters обрезаны некорректно

2.CNN для идентификации слов или cells как NUMBER или OTHER Причина в том, что различия между числами и словами более семантические (однако, обнаружен паттерн различия) Паттерн: если текст - число -> whitespaces больше. Основная проблема, которую трудно преодолеть (те же whitespaces между словами, а не characters)

3.Общий pipeline является ручным Это означает: если кто-то захочет ввести изображение таблицы и получить csv в качестве результата, в настоящее время нет основного файла для выполнения этой последовательности действий

4.Размер cells был принесен в жертву; то есть в финальном table_visualization.png cells не имеют исходного размера: вызывает дополнительные ошибки

5.Хотя код успешно реализован, он полагается на предопределенное количество строк и столбцов (может быть легко решено)

6.Хотя код успешно реализован, он полагается на предопределенный OCR tool для идентификации типа blob

ПОЛЕЗНЫЕ, Кастомные ТЕХНИКИ:
1.Для корректного обнаружения линий в таблице, они были сначала идентифицированы, и после heuristic function прорисовывает их, чтобы заполнить пробелы / дыры, если они небольшие 
Результат: все линии в таблице идентифицированы корректно: результат хранится в steps_out/horiz_mask_after.png

2.Удаление почти черных границ из cells (src/seg_cells.py) 
Решение: проверить каждые 3 строки или столбца pixels в изображении каждой cell, и если обнаружен паттерн линии, считать это линией -> удалить эту строку/столбец pixels Причина: черные границы вызывают много ошибок при корректной идентификации blobs и words

3.Для characters, расположенных слишком близко друг к другу. 
Критично для чисел Почему: предполагая, что на текущем этапе мы жертвуем качеством characters букв, некоторые characters чисел были расположены слишком близко друг к другу 
Решение: найти местоположение и индексы столбцов и строк, где character находится на изображении, и если соотношение width/height не корректно для одного character, разделить симметрично на 2 или 3 characters на основе соотношения

4.Data augmentation для генерации синтетических данных: 
Проблема: несмотря на визуальное сходство тестовых и реальных изображений, и высокую точность на синтетических данных, при попытке на реальных данных -> провал - почти менее 30% 
Решение: подать - обучить на небольшом batch реальных данных (heuristic knowledge), -> достигнутый результат -> 85%


ОСНОВНЫЕ ПРОБЛЕМЫ СЕЙЧАС:

1.Characters букв разделены некорректно

2.Размер cells был принесен в жертву; то есть в финальном table_visualization.png cells не имеют исходного размера: вызывает дополнительные ошибки

3.текущий механизм таков: если какой-либо character слова был идентифицирован как число, то все слово - число. Почему? без этого текущая cnn пропускает огромное количество чисел

INSIGHTS О РАЗЛИЧИИ МЕЖДУ WORDS И NUMBERS:
1.Whitespaces -> числа имеют значительно стабильную ширину whitespaces, и она визуально шире, чем для words

2.высота чисел обычно больше и стабильнее, чем для words (буквы могут быть в верхнем и нижнем регистре)

3.Основное различие для моделей, таких как RandomForest и XGBOOST (лучшие результаты): первые 2 и последние 2 столбца pixels каждого character, их интенсивность важна для определения того, как character начинается и заканчивается

4.При обучении RandomForest для классификации, является ли слово числом, основными features, которые варьировались для разных чисел, были: 

Dark fraction 
Col_peaks 
Columns count
 Frequency white
 Average Peak width
 Compactness 
Vertical intensity variance 
(МОЖНО увидеть результаты в temporary_compare/feature_pairs_old.png)

ОСНОВНЫЕ ИСПОЛЬЗУЕМЫЕ МЕТОДЫ АНАЛИЗА ДАННЫХ
1.Визуальный осмотр изображений (inspect_cells_production_cell_r0_c3.png, например)
2.Анализ гистограмм (temporary_compare/feature_distributions copy.png, например)
3.Feature engineering и корреляционный анализ (temporary_compare/feature_pairs_old.png, например) 4. Feature importance на основе модели (temporary_compare/features_importance_RandomForest.png) 5. Тепловая карта корреляции (Heatmap of correlation) (temporary_compare/feature_correlation_heatmap.png) -> анализ: являются ли все features запутывающими/неинформативными или их количество сбивает с толку

ПОДХОДЫ, КОТОРЫЕ БЫЛИ ПОПРОБОВАНЫ И ПРОВАЛИЛИСЬ / НЕ РЕАЛИЗОВАНЫ
1.Определение по whitespace в верхних строках characters и в нижних строках characters

2.Написание вручную алгоритма для идентификации characters (только digits)

ТЕСТОВЫЕ СЛУЧАИ ДЛЯ БЫСТРОГО ОБЗОРА
Чтобы увидеть, как разделяются cells -> 
запустить utils/preprocessing.py 

Чтобы протестировать, как CNN идентифицирует слово как NUMBER или Other: 
запустить src/test_character_classifier.py 

Чтобы протестировать, как CNN идентифицирует digits:
запустить src/test_digits_model.py

Чтобы увидеть, как восстанавливается финальная таблица: 
запустить src/combine_predictions_to_table.py 

Чтобы увидеть, как работает модель (RandomForest): 
запустить src/test_xgboost.py

ОБУЧЕННЫЕ МОДЕЛИ:

fine_tuned_real_data_classifier.keras - модель для определения digits 0-9 
 
mnt/outputs/number_detector_cnn.keras - модель для определения NUMBER или OTHER


КОМАНДА ДЛЯ ЗАПУСКА ОСНОВНОГО PIPELINE !!!!!

file: run_pipeline.py

python3 run_pipeline.py data/input/original.jpeg

