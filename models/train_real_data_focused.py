#!/usr/bin/env python3
"""
Real Data Focused CNN Training
Analyzes real images and creates training data that closely matches their characteristics
"""

import os
import numpy as np
import pandas as pd
import cv2
import random
from PIL import Image, ImageDraw, ImageFont, ImageFilter
import tensorflow as tf
from tensorflow import keras
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt

# Set random seeds for reproducibility
np.random.seed(42)
tf.random.set_seed(42)
random.seed(42)

print("=" * 70)
print("REAL DATA FOCUSED CNN TRAINING")
print("Analyzing real images and creating matching training data")
print("=" * 70)
print(f"TensorFlow version: {tf.__version__}")
print(f"Keras version: {keras.__version__}")

def analyze_real_images():
    """Analyze characteristics of real images"""
    print("\nüîç Analyzing real images...")
    
    predictions_df = pd.read_csv('experiments/predictions.csv')
    
    characteristics = {
        'mean_intensities': [],
        'std_intensities': [],
        'text_ratios': [],
        'blur_levels': []
    }
    
    for idx, row in predictions_df.iterrows():
        filename = row['filename']
        image_path = f'tests/{filename}'
        
        if os.path.exists(image_path):
            img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
            if img is not None:
                # Analyze characteristics
                mean_intensity = np.mean(img)
                std_intensity = np.std(img)
                
                # Text ratio (dark pixels vs light pixels)
                dark_pixels = np.sum(img < 128)
                total_pixels = img.shape[0] * img.shape[1]
                text_ratio = dark_pixels / total_pixels
                
                # Estimate blur level using Laplacian variance
                blur_level = cv2.Laplacian(img, cv2.CV_64F).var()
                
                characteristics['mean_intensities'].append(mean_intensity)
                characteristics['std_intensities'].append(std_intensity)
                characteristics['text_ratios'].append(text_ratio)
                characteristics['blur_levels'].append(blur_level)
    
    # Calculate statistics
    stats = {}
    for key, values in characteristics.items():
        if values:
            stats[key] = {
                'mean': np.mean(values),
                'std': np.std(values),
                'min': np.min(values),
                'max': np.max(values)
            }
    
    print(f"üìä Real image characteristics:")
    print(f"  Mean intensity: {stats['mean_intensities']['mean']:.1f} ¬± {stats['mean_intensities']['std']:.1f}")
    print(f"  Text ratio: {stats['text_ratios']['mean']:.3f} ¬± {stats['text_ratios']['std']:.3f}")
    print(f"  Blur level: {stats['blur_levels']['mean']:.1f} ¬± {stats['blur_levels']['std']:.1f}")
    
    return stats

class RealDataGenerator:
    def __init__(self, img_size=32, real_stats=None):
        self.img_size = img_size
        self.real_stats = real_stats
        self.fonts = self.load_fonts()
        
    def load_fonts(self):
        """Load available fonts"""
        print("\nLoading fonts...")
        font_paths = [
            "/System/Library/Fonts/Arial.ttf",
            "/System/Library/Fonts/Helvetica.ttc", 
            "/System/Library/Fonts/Times.ttc"
        ]
        
        fonts = []
        for font_path in font_paths:
            if os.path.exists(font_path):
                try:
                    # Use sizes that match real data better
                    for size in [18, 20, 22, 24]:
                        fonts.append(ImageFont.truetype(font_path, size))
                except:
                    pass
        
        if not fonts:
            fonts = [ImageFont.load_default()]
        
        print(f"Loaded {len(fonts)} font variations")
        return fonts
    
    def create_realistic_digit(self, digit, font):
        """Create digit image that closely matches real data characteristics"""
        # Create light background matching real data
        if self.real_stats:
            bg_intensity = np.random.normal(
                self.real_stats['mean_intensities']['mean'], 
                self.real_stats['mean_intensities']['std'] * 0.5
            )
            bg_intensity = np.clip(bg_intensity, 200, 255)
        else:
            bg_intensity = random.randint(240, 255)
        
        img = Image.new('L', (self.img_size, self.img_size), color=int(bg_intensity))
        draw = ImageDraw.Draw(img)
        
        # Dark text color with variation
        text_color = random.randint(0, 80)  # Dark text
        
        # Calculate text position for centering with slight variation
        bbox = draw.textbbox((0, 0), str(digit), font=font)
        text_width = bbox[2] - bbox[0]
        text_height = bbox[3] - bbox[1]
        
        x = (self.img_size - text_width) // 2 + random.randint(-3, 3)
        y = (self.img_size - text_height) // 2 + random.randint(-3, 3)
        
        # Draw the digit
        draw.text((x, y), str(digit), fill=text_color, font=font)
        
        # Convert to numpy array
        img_array = np.array(img)
        
        # Add realistic variations matching real data
        # 1. Add slight noise
        noise = np.random.normal(0, 2, img_array.shape)
        img_array = np.clip(img_array + noise, 0, 255)
        
        # 2. Add slight blur occasionally (matching real blur levels)
        if random.random() < 0.4:
            if self.real_stats:
                blur_sigma = np.random.normal(0.5, 0.2)
                blur_sigma = np.clip(blur_sigma, 0.1, 1.0)
            else:
                blur_sigma = random.uniform(0.2, 0.8)
            
            img_pil = Image.fromarray(img_array.astype(np.uint8))
            img_pil = img_pil.filter(ImageFilter.GaussianBlur(radius=blur_sigma))
            img_array = np.array(img_pil)
        
        # 3. Add slight compression artifacts occasionally
        if random.random() < 0.2:
            # Simulate JPEG compression
            img_pil = Image.fromarray(img_array.astype(np.uint8))
            # Save and reload with compression
            import io
            buffer = io.BytesIO()
            img_pil.save(buffer, format='JPEG', quality=random.randint(70, 90))
            buffer.seek(0)
            img_pil = Image.open(buffer)
            img_array = np.array(img_pil)
        
        return img_array.astype(np.uint8)
    
    def generate_focused_dataset(self, samples_per_digit=1000, problematic_boost=1.5):
        """Generate dataset focused on real data characteristics"""
        print(f"\nGenerating focused dataset...")
        print(f"- Base samples per digit: {samples_per_digit}")
        print(f"- Problematic digits boost: {problematic_boost}x")
        
        # Focus on the most problematic digits from real data
        problematic_digits = [0, 3, 5, 8]
        
        all_images = []
        all_labels = []
        
        for digit in range(10):
            # Calculate samples for this digit
            if digit in problematic_digits:
                num_samples = int(samples_per_digit * problematic_boost)
                print(f"  Generating digit '{digit}' ({num_samples} samples - BOOSTED) ‚úì")
            else:
                num_samples = samples_per_digit
                print(f"  Generating digit '{digit}' ({num_samples} samples) ‚úì")
            
            for i in range(num_samples):
                font = random.choice(self.fonts)
                img = self.create_realistic_digit(digit, font)
                
                all_images.append(img)
                all_labels.append(digit)
        
        # Convert to numpy arrays
        X = np.array(all_images)
        y = np.array(all_labels)
        
        # Normalize and reshape
        X = X.astype(np.float32) / 255.0
        X = X.reshape(-1, self.img_size, self.img_size, 1)
        
        print(f"\n‚úì Dataset generation complete!")
        print(f"  - Total samples: {len(X)}")
        print(f"  - Shape: {X.shape}")
        print(f"  - Value range: [{X.min():.3f}, {X.max():.3f}]")
        
        return X, y

def build_focused_cnn():
    """Build CNN optimized for real data characteristics"""
    model = keras.Sequential([
        # Input layer
        keras.layers.Input(shape=(32, 32, 1)),
        
        # First conv block - detect basic features
        keras.layers.Conv2D(16, (5, 5), activation='relu', padding='same'),
        keras.layers.BatchNormalization(),
        keras.layers.MaxPooling2D((2, 2)),
        keras.layers.Dropout(0.2),
        
        # Second conv block - detect digit patterns
        keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same'),
        keras.layers.BatchNormalization(),
        keras.layers.MaxPooling2D((2, 2)),
        keras.layers.Dropout(0.2),
        
        # Third conv block - fine details
        keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),
        keras.layers.BatchNormalization(),
        keras.layers.GlobalAveragePooling2D(),
        
        # Dense layers - conservative to avoid overfitting
        keras.layers.Dense(128, activation='relu'),
        keras.layers.BatchNormalization(),
        keras.layers.Dropout(0.4),
        
        keras.layers.Dense(64, activation='relu'),
        keras.layers.Dropout(0.3),
        
        # Output layer
        keras.layers.Dense(10, activation='softmax')
    ], name='FocusedDigitCNN')
    
    return model

def test_on_real_images():
    """Test the trained model on real images"""
    print("\n" + "=" * 70)
    print("TESTING ON REAL IMAGES")
    print("=" * 70)
    
    # Load the ground truth
    predictions_df = pd.read_csv('experiments/predictions.csv')
    
    # Load the trained model
    model = keras.models.load_model('models/focused_real_data_classifier.keras')
    
    print(f"üìÅ Found {len(predictions_df)} test images")
    print("üéØ Testing with ground truth labels...")
    
    results = []
    correct_predictions = 0
    
    print("\nüîç Testing images:")
    print("-" * 50)
    
    for idx, row in predictions_df.iterrows():
        filename = row['filename']
        true_label = int(row['predicted_class'])  # This is actually the correct label
        
        # Load and preprocess image
        image_path = f'tests/{filename}'
        if not os.path.exists(image_path):
            print(f"‚ùå Image not found: {image_path}")
            continue
            
        # Load image
        img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
        if img is None:
            print(f"‚ùå Could not load: {image_path}")
            continue
        
        # Preprocess (no inversion needed - model trained on same polarity)
        img = cv2.resize(img, (32, 32), interpolation=cv2.INTER_AREA)
        img = img.astype(np.float32) / 255.0
        img = img.reshape(1, 32, 32, 1)
        
        # Predict
        prediction = model.predict(img, verbose=0)
        predicted_digit = np.argmax(prediction)
        confidence = prediction[0][predicted_digit]
        
        # Check if correct
        is_correct = predicted_digit == true_label
        if is_correct:
            correct_predictions += 1
        
        # Store result
        results.append({
            'filename': filename,
            'true_label': true_label,
            'predicted_label': predicted_digit,
            'confidence': confidence,
            'correct': is_correct
        })
        
        # Print result
        status = "‚úÖ" if is_correct else "‚ùå"
        short_name = filename[:30] + "..." if len(filename) > 30 else filename
        print(f"{idx+1:2d}. {short_name:<33} Expected: {true_label} | Predicted: {predicted_digit} | Conf: {confidence:.4f} {status}")
    
    # Calculate accuracy
    accuracy = correct_predictions / len(results) if results else 0
    avg_confidence = np.mean([r['confidence'] for r in results]) if results else 0
    
    print("\n" + "=" * 70)
    print("üìä FINAL RESULTS")
    print("=" * 70)
    
    true_labels = [r['true_label'] for r in results]
    predicted_labels = [r['predicted_label'] for r in results]
    
    print(f"Expected:  {true_labels}")
    print(f"Predicted: {predicted_labels}")
    print(f"Accuracy:  {correct_predictions}/{len(results)} = {accuracy:.1%}")
    print(f"Avg Confidence: {avg_confidence:.3f}")
    
    # Analyze problematic digits
    problematic_digits = [0, 3, 5, 8]
    problematic_correct = 0
    problematic_total = 0
    
    for result in results:
        if result['true_label'] in problematic_digits:
            problematic_total += 1
            if result['correct']:
                problematic_correct += 1
    
    if problematic_total > 0:
        problematic_accuracy = problematic_correct / problematic_total
        print(f"Problematic digits (0,3,5,8): {problematic_correct}/{problematic_total} = {problematic_accuracy:.1%}")
    
    print("=" * 70)
    
    return results

def main():
    # Create output directory
    os.makedirs('models', exist_ok=True)
    
    # Analyze real images first
    real_stats = analyze_real_images()
    
    # Generate focused dataset
    generator = RealDataGenerator(real_stats=real_stats)
    X, y = generator.generate_focused_dataset(samples_per_digit=600, problematic_boost=2.0)
    
    # Split dataset
    print("\nSplitting dataset...")
    X_train, X_val, y_train, y_val = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    print(f"  - Training: {len(X_train)} samples")
    print(f"  - Validation: {len(X_val)} samples")
    
    # Build model
    print("\nBuilding focused CNN...")
    model = build_focused_cnn()
    
    # Compile with balanced approach
    model.compile(
        optimizer=keras.optimizers.Adam(learning_rate=0.001),
        loss='sparse_categorical_crossentropy',
        metrics=['accuracy']
    )
    
    print("\nModel Architecture:")
    print("=" * 50)
    model.summary()
    
    # Training callbacks
    callbacks = [
        keras.callbacks.EarlyStopping(
            monitor='val_accuracy',
            patience=10,
            restore_best_weights=True,
            verbose=1
        ),
        keras.callbacks.ReduceLROnPlateau(
            monitor='val_loss',
            factor=0.5,
            patience=5,
            min_lr=1e-6,
            verbose=1
        )
    ]
    
    # Train model
    print(f"\nTraining focused model...")
    history = model.fit(
        X_train, y_train,
        batch_size=32,
        epochs=50,
        validation_data=(X_val, y_val),
        callbacks=callbacks,
        verbose=1
    )
    
    # Evaluate
    print("\nüìä Validation Results:")
    val_loss, val_accuracy = model.evaluate(X_val, y_val, verbose=0)
    print(f"Validation Accuracy: {val_accuracy:.4f} ({val_accuracy*100:.2f}%)")
    
    # Save model
    model_path = 'models/focused_real_data_classifier.keras'
    model.save(model_path)
    print(f"\n‚úÖ Model saved to: {model_path}")
    
    # Test on real images
    test_results = test_on_real_images()
    
    return model, history, test_results

if __name__ == "__main__":
    model, history, results = main()
